{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b863169",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ee9b4",
   "metadata": {},
   "source": [
    "# Imports\n",
    "## Pip Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4aebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    new_directory_path = \"..\\\\..\\\\\"\n",
    "    os.chdir(new_directory_path)\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import math\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57717557",
   "metadata": {},
   "source": [
    "## My Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea0616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import CocoFreeView\n",
    "from src.simulation import gen_gaze, downsample\n",
    "from src.noise import add_random_center_correlated_radial_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c7b40b",
   "metadata": {},
   "source": [
    "# Code\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "795ed3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(mask, fixation, side = 'right'):\n",
    "    start = 0\n",
    "    stop = mask.shape[0]\n",
    "    step = 1\n",
    "    if side == 'left':\n",
    "        start = mask.shape[0] - 1 \n",
    "        stop = -1\n",
    "        step = -1\n",
    "\n",
    "    for i in range(start,stop, step):\n",
    "        if mask[i] == fixation:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def test_segment_is_inside(x, si,ei,gaze, fixation_mask):\n",
    "    sidx = search(fixation_mask, si + 1, side = 'right')\n",
    "    eidx = search(fixation_mask, ei + 1, side = 'left')\n",
    "    if sidx == -1:\n",
    "        print(f'❌ Start Fixation not found: si:{si + 1} \\n {fixation_mask}')\n",
    "    if eidx == -1:\n",
    "        print(f'❌ End Fixation not found: si:{si + 1} \\n {fixation_mask}')\n",
    "    # print(fixation_mask.shape)\n",
    "    # print(si)\n",
    "    # print(ei)\n",
    "    # print(sidx)\n",
    "    # print(eidx)\n",
    "    if x[2,0] <= gaze[2,sidx] and (x[2,-1] + 200) >= gaze[2,eidx]:\n",
    "        print(f'✅Pass: DS [{x[2,0]},{x[2,-1]}] Ori [{gaze[2,sidx]},{gaze[2,eidx]}]')\n",
    "    else:\n",
    "        print(f'❌Outside: DS [{x[2,0]},{x[2,-1]}] Ori [{gaze[2,sidx]},{gaze[2,eidx]}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4012500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Compute image embeddings just once\n",
    "\n",
    "class PathCocoFreeViewDataset(Dataset):\n",
    "    '''\n",
    "    The noisy and downsampled simulated eye-tracking and the section of the scanpath that fits entirely in that part\n",
    "    '''\n",
    "\n",
    "    def __init__(self,data_path = 'data\\\\Coco FreeView', sample_size=-1, sampling_rate=60, downsample=200, min_scanpath_duration = 3000, max_fixation_duration = 1200, log = False, debug = False):\n",
    "        super().__init__()\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.sample_size = sample_size # 90% larger than 20 at downsample 200\n",
    "        self.downsample = downsample\n",
    "        self.min_scanpath_duration = min_scanpath_duration\n",
    "        self.max_fixation_duration = max_fixation_duration\n",
    "        self.log = log\n",
    "        self.debug = debug\n",
    "        self.h5_path = os.path.join(data_path, 'dataset.hdf5')\n",
    "        if not os.path.exists(self.h5_path):\n",
    "            if self.log:\n",
    "                print('gen data file not found')\n",
    "                print('generating data')\n",
    "            self.__preprocess()\n",
    "        self.data = h5py.File(self.h5_path,'r')\n",
    "        \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        # TODO change len for new data structure\n",
    "        return self.data['down_gaze'].shape[0]\n",
    "    \n",
    "\n",
    "    def __preprocess(self):\n",
    "        # TODO gen all the clean samples\n",
    "        data = CocoFreeView()\n",
    "        gen_data = []\n",
    "        original_data_count = len(data)\n",
    "        for index in range(original_data_count):\n",
    "            gaze, fixations, fixation_mask = gen_gaze(data,\n",
    "                                                        index, self.sampling_rate,\n",
    "                                                        get_scanpath=True,\n",
    "                                                        get_fixation_mask=True)\n",
    "            down_gaze = downsample(gaze, down_time_step=self.downsample)\n",
    "            if (gaze[2,-1] < max(self.min_scanpath_duration, (self.sample_size - 1)*self.downsample) or\n",
    "                fixations[2].max() > self.max_fixation_duration) :\n",
    "                continue\n",
    "            gen_data.append({'down_gaze': down_gaze,\n",
    "                             'fixations': fixations,\n",
    "                             'fixation_mask': fixation_mask,\n",
    "                             'gaze': gaze})\n",
    "        if self.log:\n",
    "            removed = original_data_count - len(gen_data)\n",
    "            print(f'Removed: {removed} - {(removed/original_data_count)*100}% ')\n",
    "        # save\n",
    "        with h5py.File(self.h5_path, 'w') as f:\n",
    "            # Create datasets with shape (43000,) and the vlen dtype\n",
    "            item = gen_data[0]\n",
    "            k_dset = dict()\n",
    "            for k in item.keys():\n",
    "                k_dset[k] = f.create_dataset(k, len(gen_data), dtype= h5py.special_dtype(vlen= item[k].dtype))\n",
    "\n",
    "\n",
    "            # Loop and store each item\n",
    "            for i, item in enumerate(gen_data):\n",
    "                for k in item.keys():\n",
    "                    if item[k].ndim > 1:\n",
    "                        k_dset[k][i] = item[k].flatten()\n",
    "                    else:\n",
    "                        k_dset[k][i] = item[k]\n",
    "        \n",
    "        if self.log:\n",
    "            print('generated items saved')\n",
    "\n",
    "\n",
    "    def __extract_random_period(self, size, noisy_samples, fixations, fixation_mask):\n",
    "        down_idx = np.random.randint(0, noisy_samples.shape[1] - size + 1, 1, dtype = int)[0]\n",
    "        # get the values in the original sampling rate\n",
    "        conversion_factor = self.downsample/(1000/self.sampling_rate)\n",
    "        ori_idx = math.floor(down_idx*conversion_factor)\n",
    "        ori_size = math.ceil((size - 1)*conversion_factor)\n",
    "        last_idx = ori_idx + ori_size\n",
    "        # TEST\n",
    "        # get the fisrt fixation and if it is not completely included get the next one\n",
    "        if fixation_mask[ori_idx] > 0:\n",
    "            if (ori_idx - 1) >= 0 and fixation_mask[ori_idx - 1] == fixation_mask[ori_idx]:\n",
    "                start_fixation = fixation_mask[ori_idx] + 1\n",
    "            else:\n",
    "                start_fixation = fixation_mask[ori_idx]\n",
    "        else:\n",
    "            # if the first value is a saccade look for the first fixation\n",
    "            current_idx = ori_idx + 1\n",
    "            while current_idx < (ori_idx + ori_size) and fixation_mask[current_idx] == 0:\n",
    "                current_idx += 1\n",
    "            if current_idx == (ori_idx + ori_size):\n",
    "                # if there is not a fixation return an empty array\n",
    "                return noisy_samples[:, down_idx:down_idx + size],np.array([]), -1,-1\n",
    "            else:\n",
    "                # TEST\n",
    "                start_fixation = fixation_mask[current_idx]\n",
    "        # search the last fixation\n",
    "        if fixation_mask[last_idx] > 0:\n",
    "            if (last_idx + 1) < fixation_mask.shape[0] and fixation_mask[last_idx + 1] == fixation_mask[last_idx]:\n",
    "                end_fixation = fixation_mask[last_idx] - 1\n",
    "            else:\n",
    "                end_fixation = fixation_mask[last_idx]\n",
    "        else:\n",
    "            current_idx = last_idx - 1\n",
    "            while current_idx > ori_idx and fixation_mask[current_idx] == 0:\n",
    "                current_idx -= 1\n",
    "            end_fixation = fixation_mask[current_idx]\n",
    "        # the mask are saved shifted in order to assign 0 to the saccade samples\n",
    "        start_fixation -= 1\n",
    "        end_fixation -= 1\n",
    "        x = noisy_samples[:, down_idx:down_idx + size]\n",
    "        y = fixations[:, start_fixation: end_fixation + 1]\n",
    "        return x, y, start_fixation, end_fixation\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        down_gaze = self.data['down_gaze'][index].reshape((3,-1))\n",
    "        fixations = self.data['fixations'][index].reshape((3,-1))\n",
    "        x = down_gaze        \n",
    "        y = fixations\n",
    "        if self.sample_size != -1:\n",
    "            fixation_mask = self.data['fixation_mask'][index]\n",
    "            x, y, start_fixation, end_fxation = self.__extract_random_period(self.sample_size,\n",
    "                                                x,\n",
    "                                                fixations,\n",
    "                                                fixation_mask)\n",
    "            if start_fixation != -1:\n",
    "                gaze = self.data['gaze'][index].reshape((3,-1))\n",
    "                test_segment_is_inside(x,start_fixation, end_fxation,gaze, fixation_mask)\n",
    "\n",
    "        x, _ = add_random_center_correlated_radial_noise(x, [320//2, 512//2], 1/16,\n",
    "                                                                  radial_corr=.2,\n",
    "                                                                  radial_avg_norm=4.13,\n",
    "                                                                  radial_std=3.5,\n",
    "                                                                  center_noise_std=100,\n",
    "                                                                  center_corr=.3,\n",
    "                                                                  center_delta_norm=300,\n",
    "                                                                  center_delta_r=.3)\n",
    "        return x, y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f33bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PathCocoFreeViewDataset(sample_size=-1,log = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83410f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39869/39869 [00:15<00:00, 2630.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    dataset[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
