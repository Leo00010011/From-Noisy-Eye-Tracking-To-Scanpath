defaults:
  - scheduler: multistep_lr
  - data: default
  - model: mixer_model
  - loss: separated_loss
  - _self_

training:
  num_epochs: 100
  validate: True
  val_interval: 10
  learning_rate: 0.0001
  decisive_metric: "reg_error_val"
  use_denoise_dropout_scheduler: False
  # pretrained_model: "outputs/2026-01-17/14-01-07"
  save_best_only: True
  save_full_state: True
  use_scheduled_sampling: False
  weight_decay: 0.01
  log: True
  weights_scheduler:
    enabled: False
    init_b: 0.8
    end_b: 0.999
    alpha: 10
    epochs: 50
  Phases: ["Denoise"]
  Denoise:
    name: "Denoise"
    denoise_weight: 1 
    decisive_metric: "denoise_error_val"
    epochs: 150
  Fixation:
    name: "Fixation"
    denoise_weight: 0
    decisive_metric: ${training.decisive_metric}
    epochs: 40
  Combined:
    name: "Combined"
    denoise_weight: 0.05
    decisive_metric: ${training.decisive_metric}
    epochs: 120

loss:
  complex_type: "combined"
  denoise_loss_type: "l1"
  fixation_loss_type: "separated_reg"
scheduled_sampling:
  warmup_epochs: 30
  active_epochs: 40
  n_updates: -1
  min_prob: 0
denoise_dropout_scheduler:
  base_prob: 0.2
  warmup_epochs: 20
  active_epochs: 50
